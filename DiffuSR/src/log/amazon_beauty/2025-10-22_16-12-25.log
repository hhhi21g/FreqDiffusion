2025/10/22 16:12:25 - __main__ - INFO - 115 - main - Namespace(dataset='amazon_beauty', log_file='log/', random_seed=1997, max_len=50, device=device(type='cuda', index=0), num_gpu=1, batch_size=512, hidden_size=128, dropout=0.1, emb_dropout=0.3, hidden_act='gelu', num_blocks=4, epochs=500, decay_step=100, gamma=0.1, metric_ks=[5, 10, 20], optimizer='Adam', lr=0.001, loss_lambda=0, weight_decay=1e-05, momentum=None, schedule_sampler_name='lossaware', diffusion_steps=32, lambda_uncertainty=0.001, noise_schedule='trunc_lin', rescale_timesteps=True, eval_interval=20, patience=5, description='Diffu_norm_score', long_head=False, diversity_measure=False, epoch_time_avg=False, model='freqdiffusion', maxlen=200, hidden_units=50, num_epochs=1000, num_heads=1, dropout_rate=0.2, l2_emb=0.0, inference_only=False, state_dict_path=None, norm_first=False)
2025/10/22 16:12:31 - __main__ - INFO - 104 - trainer - Epoch: 0
2025/10/22 16:12:36 - __main__ - INFO - 139 - trainer - [0/257] Loss: 49.7827
2025/10/22 16:12:50 - __main__ - INFO - 139 - trainer - [52/257] Loss: 31.5351
2025/10/22 16:13:05 - __main__ - INFO - 139 - trainer - [104/257] Loss: 25.2558
2025/10/22 16:13:19 - __main__ - INFO - 139 - trainer - [156/257] Loss: 22.3415
2025/10/22 16:13:34 - __main__ - INFO - 139 - trainer - [208/257] Loss: 20.0903
2025/10/22 16:13:48 - __main__ - INFO - 104 - trainer - Epoch: 1
2025/10/22 16:13:49 - __main__ - INFO - 139 - trainer - [0/257] Loss: 18.2124
2025/10/22 16:14:05 - __main__ - INFO - 139 - trainer - [52/257] Loss: 16.1382
2025/10/22 16:14:19 - __main__ - INFO - 139 - trainer - [104/257] Loss: 14.3108
2025/10/22 16:14:36 - __main__ - INFO - 139 - trainer - [156/257] Loss: 12.9568
2025/10/22 16:14:51 - __main__ - INFO - 139 - trainer - [208/257] Loss: 11.1314
2025/10/22 16:15:05 - __main__ - INFO - 104 - trainer - Epoch: 2
2025/10/22 16:15:05 - __main__ - INFO - 139 - trainer - [0/257] Loss: 10.2674
2025/10/22 16:15:20 - __main__ - INFO - 139 - trainer - [52/257] Loss: 9.9854
2025/10/22 16:15:35 - __main__ - INFO - 139 - trainer - [104/257] Loss: 9.8510
2025/10/22 16:15:50 - __main__ - INFO - 139 - trainer - [156/257] Loss: 9.8238
2025/10/22 16:16:05 - __main__ - INFO - 139 - trainer - [208/257] Loss: 9.7230
2025/10/22 16:16:20 - __main__ - INFO - 104 - trainer - Epoch: 3
2025/10/22 16:16:20 - __main__ - INFO - 139 - trainer - [0/257] Loss: 9.6514
2025/10/22 16:16:36 - __main__ - INFO - 139 - trainer - [52/257] Loss: 9.5851
