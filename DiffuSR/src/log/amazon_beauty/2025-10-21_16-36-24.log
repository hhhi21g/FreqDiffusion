2025/10/21 16:36:24 - __main__ - INFO - 108 - main - Namespace(dataset='amazon_beauty', log_file='log/', random_seed=1997, max_len=50, device=device(type='cuda', index=0), num_gpu=1, batch_size=512, hidden_size=128, dropout=0.1, emb_dropout=0.3, hidden_act='gelu', num_blocks=4, epochs=500, decay_step=100, gamma=0.1, metric_ks=[5, 10, 20], optimizer='Adam', lr=0.001, loss_lambda=0.001, weight_decay=0, momentum=None, schedule_sampler_name='lossaware', diffusion_steps=32, lambda_uncertainty=0.001, noise_schedule='trunc_lin', rescale_timesteps=True, eval_interval=20, patience=5, description='Diffu_norm_score', long_head=False, diversity_measure=False, epoch_time_avg=False, model='sasrec', maxlen=200, hidden_units=50, num_epochs=1000, num_heads=1, dropout_rate=0.2, l2_emb=0.0, inference_only=False, state_dict_path=None, norm_first=False)
2025/10/21 16:36:26 - __main__ - INFO - 108 - trainer - Epoch: 0
2025/10/21 16:36:27 - __main__ - INFO - 156 - trainer - [0/257] Loss: 4.1520
2025/10/21 16:36:30 - __main__ - INFO - 156 - trainer - [52/257] Loss: 3.5859
2025/10/21 16:36:32 - __main__ - INFO - 156 - trainer - [104/257] Loss: 2.9222
2025/10/21 16:36:35 - __main__ - INFO - 156 - trainer - [156/257] Loss: 4.0134
2025/10/21 16:36:38 - __main__ - INFO - 156 - trainer - [208/257] Loss: 3.5701
2025/10/21 16:36:40 - __main__ - INFO - 108 - trainer - Epoch: 1
2025/10/21 16:36:40 - __main__ - INFO - 156 - trainer - [0/257] Loss: 2.5064
2025/10/21 16:36:43 - __main__ - INFO - 156 - trainer - [52/257] Loss: 3.4048
2025/10/21 16:36:46 - __main__ - INFO - 156 - trainer - [104/257] Loss: 3.2705
2025/10/21 16:36:48 - __main__ - INFO - 156 - trainer - [156/257] Loss: 4.2266
2025/10/21 16:36:51 - __main__ - INFO - 156 - trainer - [208/257] Loss: 4.1363
2025/10/21 16:36:53 - __main__ - INFO - 108 - trainer - Epoch: 2
2025/10/21 16:36:53 - __main__ - INFO - 156 - trainer - [0/257] Loss: 3.5615
2025/10/21 16:36:56 - __main__ - INFO - 156 - trainer - [52/257] Loss: 4.2725
2025/10/21 16:36:59 - __main__ - INFO - 156 - trainer - [104/257] Loss: 3.6055
2025/10/21 16:37:01 - __main__ - INFO - 156 - trainer - [156/257] Loss: 2.8364
2025/10/21 16:37:04 - __main__ - INFO - 156 - trainer - [208/257] Loss: 2.9715
2025/10/21 16:37:07 - __main__ - INFO - 108 - trainer - Epoch: 3
2025/10/21 16:37:07 - __main__ - INFO - 156 - trainer - [0/257] Loss: 2.8084
2025/10/21 16:37:10 - __main__ - INFO - 156 - trainer - [52/257] Loss: 3.1636
2025/10/21 16:37:12 - __main__ - INFO - 156 - trainer - [104/257] Loss: 3.6134
2025/10/21 16:37:15 - __main__ - INFO - 156 - trainer - [156/257] Loss: 3.7620
2025/10/21 16:37:17 - __main__ - INFO - 156 - trainer - [208/257] Loss: 3.1453
2025/10/21 16:37:20 - __main__ - INFO - 108 - trainer - Epoch: 4
2025/10/21 16:37:20 - __main__ - INFO - 156 - trainer - [0/257] Loss: 2.8419
2025/10/21 16:37:22 - __main__ - INFO - 156 - trainer - [52/257] Loss: 3.3336
2025/10/21 16:37:25 - __main__ - INFO - 156 - trainer - [104/257] Loss: 3.4334
2025/10/21 16:37:28 - __main__ - INFO - 156 - trainer - [156/257] Loss: 3.1850
2025/10/21 16:37:30 - __main__ - INFO - 156 - trainer - [208/257] Loss: 3.4321
2025/10/21 16:37:33 - __main__ - INFO - 108 - trainer - Epoch: 5
2025/10/21 16:37:33 - __main__ - INFO - 156 - trainer - [0/257] Loss: 3.7649
2025/10/21 16:37:36 - __main__ - INFO - 156 - trainer - [52/257] Loss: 2.5420
2025/10/21 16:37:38 - __main__ - INFO - 156 - trainer - [104/257] Loss: 3.6661
2025/10/21 16:37:41 - __main__ - INFO - 156 - trainer - [156/257] Loss: 2.8126
2025/10/21 16:37:43 - __main__ - INFO - 156 - trainer - [208/257] Loss: 3.3497
2025/10/21 16:37:46 - __main__ - INFO - 108 - trainer - Epoch: 6
2025/10/21 16:37:46 - __main__ - INFO - 156 - trainer - [0/257] Loss: 3.4638
2025/10/21 16:37:48 - __main__ - INFO - 156 - trainer - [52/257] Loss: 3.2407
2025/10/21 16:37:51 - __main__ - INFO - 156 - trainer - [104/257] Loss: 3.0591
2025/10/21 16:37:53 - __main__ - INFO - 156 - trainer - [156/257] Loss: 2.8872
2025/10/21 16:37:56 - __main__ - INFO - 156 - trainer - [208/257] Loss: 2.8494
2025/10/21 16:37:59 - __main__ - INFO - 108 - trainer - Epoch: 7
2025/10/21 16:37:59 - __main__ - INFO - 156 - trainer - [0/257] Loss: 3.0297
2025/10/21 16:38:02 - __main__ - INFO - 156 - trainer - [52/257] Loss: 3.6388
2025/10/21 16:38:04 - __main__ - INFO - 156 - trainer - [104/257] Loss: 2.9544
2025/10/21 16:38:06 - __main__ - INFO - 156 - trainer - [156/257] Loss: 3.1216
2025/10/21 16:38:09 - __main__ - INFO - 156 - trainer - [208/257] Loss: 3.2765
2025/10/21 16:38:11 - __main__ - INFO - 108 - trainer - Epoch: 8
2025/10/21 16:38:11 - __main__ - INFO - 156 - trainer - [0/257] Loss: 2.9014
2025/10/21 16:38:14 - __main__ - INFO - 156 - trainer - [52/257] Loss: 3.3516
2025/10/21 16:38:17 - __main__ - INFO - 156 - trainer - [104/257] Loss: 3.0755
2025/10/21 16:38:20 - __main__ - INFO - 156 - trainer - [156/257] Loss: 2.8202
2025/10/21 16:38:22 - __main__ - INFO - 156 - trainer - [208/257] Loss: 3.2359
2025/10/21 16:38:24 - __main__ - INFO - 108 - trainer - Epoch: 9
2025/10/21 16:38:25 - __main__ - INFO - 156 - trainer - [0/257] Loss: 3.1456
2025/10/21 16:38:27 - __main__ - INFO - 156 - trainer - [52/257] Loss: 2.9173
2025/10/21 16:38:30 - __main__ - INFO - 156 - trainer - [104/257] Loss: 3.5242
2025/10/21 16:38:32 - __main__ - INFO - 156 - trainer - [156/257] Loss: 2.6435
2025/10/21 16:38:35 - __main__ - INFO - 156 - trainer - [208/257] Loss: 3.2131
2025/10/21 16:38:37 - __main__ - INFO - 108 - trainer - Epoch: 10
2025/10/21 16:38:37 - __main__ - INFO - 156 - trainer - [0/257] Loss: 3.3070
2025/10/21 16:38:40 - __main__ - INFO - 156 - trainer - [52/257] Loss: 3.1909
2025/10/21 16:38:43 - __main__ - INFO - 156 - trainer - [104/257] Loss: 2.6047
2025/10/21 16:38:46 - __main__ - INFO - 156 - trainer - [156/257] Loss: 2.9481
2025/10/21 16:38:48 - __main__ - INFO - 156 - trainer - [208/257] Loss: 3.2529
2025/10/21 16:38:50 - __main__ - INFO - 108 - trainer - Epoch: 11
2025/10/21 16:38:50 - __main__ - INFO - 156 - trainer - [0/257] Loss: 2.6669
2025/10/21 16:38:53 - __main__ - INFO - 156 - trainer - [52/257] Loss: 2.7258
2025/10/21 16:38:56 - __main__ - INFO - 156 - trainer - [104/257] Loss: 3.1425
2025/10/21 16:38:58 - __main__ - INFO - 156 - trainer - [156/257] Loss: 2.8812
2025/10/21 16:39:01 - __main__ - INFO - 156 - trainer - [208/257] Loss: 3.6667
2025/10/21 16:39:03 - __main__ - INFO - 108 - trainer - Epoch: 12
2025/10/21 16:39:03 - __main__ - INFO - 156 - trainer - [0/257] Loss: 2.3680
2025/10/21 16:39:06 - __main__ - INFO - 156 - trainer - [52/257] Loss: 2.2027
2025/10/21 16:39:09 - __main__ - INFO - 156 - trainer - [104/257] Loss: 3.0953
2025/10/21 16:39:12 - __main__ - INFO - 156 - trainer - [156/257] Loss: 1.4758
2025/10/21 16:39:14 - __main__ - INFO - 156 - trainer - [208/257] Loss: 3.2152
2025/10/21 16:39:16 - __main__ - INFO - 108 - trainer - Epoch: 13
2025/10/21 16:39:16 - __main__ - INFO - 156 - trainer - [0/257] Loss: 3.0469
2025/10/21 16:39:19 - __main__ - INFO - 156 - trainer - [52/257] Loss: 2.2749
2025/10/21 16:39:22 - __main__ - INFO - 156 - trainer - [104/257] Loss: 2.4388
2025/10/21 16:39:24 - __main__ - INFO - 156 - trainer - [156/257] Loss: 3.1755
2025/10/21 16:39:26 - __main__ - INFO - 156 - trainer - [208/257] Loss: 3.5905
2025/10/21 16:39:29 - __main__ - INFO - 108 - trainer - Epoch: 14
2025/10/21 16:39:29 - __main__ - INFO - 156 - trainer - [0/257] Loss: 2.0539
2025/10/21 16:39:32 - __main__ - INFO - 156 - trainer - [52/257] Loss: 4.0237
2025/10/21 16:39:34 - __main__ - INFO - 156 - trainer - [104/257] Loss: 3.3225
2025/10/21 16:39:37 - __main__ - INFO - 156 - trainer - [156/257] Loss: 1.6564
2025/10/21 16:39:39 - __main__ - INFO - 156 - trainer - [208/257] Loss: 3.2773
2025/10/21 16:39:42 - __main__ - INFO - 108 - trainer - Epoch: 15
2025/10/21 16:39:42 - __main__ - INFO - 156 - trainer - [0/257] Loss: 2.6968
2025/10/21 16:39:44 - __main__ - INFO - 156 - trainer - [52/257] Loss: 2.9934
2025/10/21 16:39:47 - __main__ - INFO - 156 - trainer - [104/257] Loss: 2.7161
2025/10/21 16:39:49 - __main__ - INFO - 156 - trainer - [156/257] Loss: 2.5378
2025/10/21 16:39:52 - __main__ - INFO - 156 - trainer - [208/257] Loss: 3.8099
2025/10/21 16:39:55 - __main__ - INFO - 108 - trainer - Epoch: 16
2025/10/21 16:39:55 - __main__ - INFO - 156 - trainer - [0/257] Loss: 3.3595
2025/10/21 16:39:58 - __main__ - INFO - 156 - trainer - [52/257] Loss: 3.5123
2025/10/21 16:40:00 - __main__ - INFO - 156 - trainer - [104/257] Loss: 3.3282
2025/10/21 16:40:03 - __main__ - INFO - 156 - trainer - [156/257] Loss: 3.4558
2025/10/21 16:40:05 - __main__ - INFO - 156 - trainer - [208/257] Loss: 3.4122
2025/10/21 16:40:08 - __main__ - INFO - 108 - trainer - Epoch: 17
2025/10/21 16:40:08 - __main__ - INFO - 156 - trainer - [0/257] Loss: 2.7718
2025/10/21 16:40:10 - __main__ - INFO - 156 - trainer - [52/257] Loss: 2.6702
2025/10/21 16:40:13 - __main__ - INFO - 156 - trainer - [104/257] Loss: 2.1759
2025/10/21 16:40:16 - __main__ - INFO - 156 - trainer - [156/257] Loss: 2.8189
2025/10/21 16:40:19 - __main__ - INFO - 156 - trainer - [208/257] Loss: 3.2343
2025/10/21 16:40:21 - __main__ - INFO - 108 - trainer - Epoch: 18
2025/10/21 16:40:21 - __main__ - INFO - 156 - trainer - [0/257] Loss: 1.5788
2025/10/21 16:40:24 - __main__ - INFO - 156 - trainer - [52/257] Loss: 4.7802
2025/10/21 16:40:26 - __main__ - INFO - 156 - trainer - [104/257] Loss: 2.9111
2025/10/21 16:40:29 - __main__ - INFO - 156 - trainer - [156/257] Loss: 1.2178
2025/10/21 16:40:32 - __main__ - INFO - 156 - trainer - [208/257] Loss: 2.2342
2025/10/21 16:40:34 - __main__ - INFO - 108 - trainer - Epoch: 19
2025/10/21 16:40:34 - __main__ - INFO - 156 - trainer - [0/257] Loss: 1.3202
2025/10/21 16:40:37 - __main__ - INFO - 156 - trainer - [52/257] Loss: 2.5363
2025/10/21 16:40:39 - __main__ - INFO - 156 - trainer - [104/257] Loss: 3.0056
2025/10/21 16:40:42 - __main__ - INFO - 156 - trainer - [156/257] Loss: 1.2417
2025/10/21 16:40:45 - __main__ - INFO - 156 - trainer - [208/257] Loss: 3.3367
2025/10/21 16:40:47 - __main__ - INFO - 108 - trainer - Epoch: 20
2025/10/21 16:40:47 - __main__ - INFO - 156 - trainer - [0/257] Loss: 1.1938
2025/10/21 16:40:50 - __main__ - INFO - 156 - trainer - [52/257] Loss: 2.3127
2025/10/21 16:40:53 - __main__ - INFO - 156 - trainer - [104/257] Loss: 2.5596
2025/10/21 16:40:55 - __main__ - INFO - 156 - trainer - [156/257] Loss: 2.0883
2025/10/21 16:40:58 - __main__ - INFO - 156 - trainer - [208/257] Loss: 1.5536
2025/10/21 16:41:00 - __main__ - INFO - 162 - trainer - start predicting: 2025-10-21 16:41:00.560853
